{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "rSJHlBDQdaRw",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/Logos/organization_logo/organization_logo.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "vMVU_umFdaR2",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "bzBD9ALTdaR5",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "riXGnnbedaR7",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "    \n",
    "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
    "2. <a href=\"#item32\">Download Data</a>  \n",
    "3. <a href=\"#item33\">Define Global Constants</a>  \n",
    "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
    "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "Nu1PBwVCdaR9",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "Mg9aRZTqdaSA",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item31'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "CEUkJKftdaSC",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "uNFyTALddaSF",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "2eI6ogiEdaSG",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 99
    },
    "colab_type": "code",
    "deletable": true,
    "id": "_D5lERAhdaSI",
    "new_sheet": false,
    "outputId": "227b9e82-d4e0-437e-90e3-9c68f8d2e8e7",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "fi3ytvr2daSO",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "id": "9Oq2Y12-daSQ",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "Lt2Ae44_daSX",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "id": "wUfsLXFsdaSZ",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "oQEULw3ydaSi",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "LQEKJAAedaSk",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "g6mzf5pYdaSm",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "deletable": true,
    "id": "Bkwg57m9daSo",
    "new_sheet": false,
    "outputId": "a685d9dc-0ba1-42e9-b1da-a3965cd89877",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-24 09:47:27--  https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip\n",
      "Resolving s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)... 67.228.254.196\n",
      "Connecting to s3-api.us-geo.objectstorage.softlayer.net (s3-api.us-geo.objectstorage.softlayer.net)|67.228.254.196|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 261482368 (249M) [application/zip]\n",
      "Saving to: ‘concrete_data_week3.zip.6’\n",
      "\n",
      "concrete_data_week3 100%[===================>] 249.37M  23.9MB/s    in 12s     \n",
      "\n",
      "2020-03-24 09:47:39 (20.4 MB/s) - ‘concrete_data_week3.zip.6’ saved [261482368/261482368]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## get the data\n",
    "!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "reLNJXGQdaSw",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file *concrete_data_week3.zip* appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "deletable": true,
    "id": "Fsf-a-cEdaSy",
    "new_sheet": false,
    "outputId": "14ff71d8-311a-4c7c-e67d-2c72ba3ac8ab",
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  concrete_data_week3.zip\n",
      "replace concrete_data_week3/valid/positive/16679_1.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!unzip concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "UJjAfG-fdaS6",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "48OADFpYdaS8",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50*** error. So please **DO NOT DO IT**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "v_Cv0x9XdaS-",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item33'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "5HYppuArdaTA",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "fys3gSP4daTC",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab. \n",
    "\n",
    "1. We are obviously dealing with two classes, so *num_classes* is 2. \n",
    "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3. We will training and validating the model using batches of 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "id": "JmDyX3tqdaTE",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "rkBvLjJDdaTK",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "275m2QrDdaTM",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "36DRUkIwdaTP",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "id": "wwt7Y6pDdaTV",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "9qWsTNC6daTc",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "deletable": true,
    "id": "X7xzOLTzdaTe",
    "new_sheet": false,
    "outputId": "5ca8a909-fc8f-4280-a39a-8e5071b1278d",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "GAeocA7IdaTm",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "deletable": true,
    "id": "RhGaO9ETdaTp",
    "new_sheet": false,
    "outputId": "faa65292-b912-4074-fd22-d7b19f2303a9",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "N_HfI8gUdaTw",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-click __here__ for the solution.\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "-oLWesCFdaTz",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "KsZYfCUzdaT1",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "s1uC87wgdaT2",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "deletable": true,
    "id": "q1-OS59jdaT3",
    "new_sheet": false,
    "outputId": "e01dc8c4-56b9-4f35-90dc-b9af135e3e93",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "aEFb72zsdaT6",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "deletable": true,
    "id": "DHT1SGIQdaT7",
    "new_sheet": false,
    "outputId": "b617ead5-f9c5-4e81-d04a-5e0cae0339f6",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94658560/94653016 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "P_pFnTyndaUB",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "deletable": true,
    "id": "nSWrFOzrdaUD",
    "new_sheet": false,
    "outputId": "5ea8ad1a-e7b2-4827-bc90-cb3518c7fde7",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "B3_DyzwsdaUJ",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the *layers* attribute of our model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "deletable": true,
    "id": "OPpPhN1IdaUL",
    "new_sheet": false,
    "outputId": "b0aab0cd-701c-4da2-ad19-09a009a0e38d",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.training.Model at 0x7ff70965b358>,\n",
       " <keras.layers.core.Dense at 0x7ff7aba83b70>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "JKj16D1ZdaUQ",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "KkE7yV57daUR",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the ResNet50 layers by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "deletable": true,
    "id": "BYMxYFH-daUT",
    "new_sheet": false,
    "outputId": "1dc07eaa-4319-40d6-e649-2c9c16c201df",
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x7ff7aba839e8>,\n",
       " <keras.layers.convolutional.ZeroPadding2D at 0x7ff7aba83940>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff8052c48d0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff7aba978d0>,\n",
       " <keras.layers.core.Activation at 0x7ff7aba97668>,\n",
       " <keras.layers.pooling.MaxPooling2D at 0x7ff7a818cac8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff7a821a908>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff7aba40ef0>,\n",
       " <keras.layers.core.Activation at 0x7ff7aa7f7eb8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff7aa748fd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff7aa7b8d68>,\n",
       " <keras.layers.core.Activation at 0x7ff7aa71ae10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff7aa653748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff7aa3ed0f0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff7aa640860>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff7aa306f98>,\n",
       " <keras.layers.merge.Add at 0x7ff7aa2f1f60>,\n",
       " <keras.layers.core.Activation at 0x7ff7a80dbc18>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff7a80dba58>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff7a810e3c8>,\n",
       " <keras.layers.core.Activation at 0x7ff7885f7cf8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff788568d68>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff788559e80>,\n",
       " <keras.layers.core.Activation at 0x7ff7884c0a90>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff7687b94e0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff76877cdd8>,\n",
       " <keras.layers.merge.Add at 0x7ff768793160>,\n",
       " <keras.layers.core.Activation at 0x7ff768730d30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff768730b70>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff74c7be5c0>,\n",
       " <keras.layers.core.Activation at 0x7ff768658e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff74c7895f8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff74c775710>,\n",
       " <keras.layers.core.Activation at 0x7ff74c763160>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff74c68fd30>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff74c681e48>,\n",
       " <keras.layers.merge.Add at 0x7ff74c666a58>,\n",
       " <keras.layers.core.Activation at 0x7ff74c35c5c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff74c35c400>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff74c329b38>,\n",
       " <keras.layers.core.Activation at 0x7ff7a806f748>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff74c2cafd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff74c226a90>,\n",
       " <keras.layers.core.Activation at 0x7ff74c183668>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff74c160ac8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff74c080e48>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff74c151be0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff74c064470>,\n",
       " <keras.layers.merge.Add at 0x7ff70bfd15c0>,\n",
       " <keras.layers.core.Activation at 0x7ff70bf48f28>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70bf48ef0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70bec27b8>,\n",
       " <keras.layers.core.Activation at 0x7ff70bea28d0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70be0c438>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70bdccdd8>,\n",
       " <keras.layers.core.Activation at 0x7ff70bda7828>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70bd0ecc0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70bd00dd8>,\n",
       " <keras.layers.merge.Add at 0x7ff70bc530f0>,\n",
       " <keras.layers.core.Activation at 0x7ff70bc0d668>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70bc0d4a8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70bbe3c18>,\n",
       " <keras.layers.core.Activation at 0x7ff70bbbcd30>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70bb22f28>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70baf9780>,\n",
       " <keras.layers.core.Activation at 0x7ff70ba57438>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70ba33898>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70ba239b0>,\n",
       " <keras.layers.merge.Add at 0x7ff70b957c50>,\n",
       " <keras.layers.core.Activation at 0x7ff70b925f60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70b925f28>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70b8917f0>,\n",
       " <keras.layers.core.Activation at 0x7ff70b86e908>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70b7cbbe0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70b83ecf8>,\n",
       " <keras.layers.core.Activation at 0x7ff70b768e10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70b6e3438>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70b6a3be0>,\n",
       " <keras.layers.merge.Add at 0x7ff70b67e860>,\n",
       " <keras.layers.core.Activation at 0x7ff70b57dcc0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70b5d5dd8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70b5bdd30>,\n",
       " <keras.layers.core.Activation at 0x7ff70b5294e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70b4f67b8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70b4e48d0>,\n",
       " <keras.layers.core.Activation at 0x7ff70b414b70>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70b3faf28>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70b330438>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70b353780>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70b2fa9b0>,\n",
       " <keras.layers.merge.Add at 0x7ff70b268b00>,\n",
       " <keras.layers.core.Activation at 0x7ff70b1fbb38>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70b1fb978>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70b1b02e8>,\n",
       " <keras.layers.core.Activation at 0x7ff70b0e2630>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70b0a3f98>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70b071a20>,\n",
       " <keras.layers.core.Activation at 0x7ff70afe05c0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70afbda20>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70afaeb38>,\n",
       " <keras.layers.merge.Add at 0x7ff70aeab278>,\n",
       " <keras.layers.core.Activation at 0x7ff70aebec88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70ae53278>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70ae12978>,\n",
       " <keras.layers.core.Activation at 0x7ff70adf2e80>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70ad58f60>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70ad309e8>,\n",
       " <keras.layers.core.Activation at 0x7ff70ac8b588>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70ac6a9e8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70ac5bb00>,\n",
       " <keras.layers.merge.Add at 0x7ff70ab8ac50>,\n",
       " <keras.layers.core.Activation at 0x7ff70ab6e550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70ab06240>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70aac8940>,\n",
       " <keras.layers.core.Activation at 0x7ff70aaa1e48>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70aa02f28>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70a9de9b0>,\n",
       " <keras.layers.core.Activation at 0x7ff70a9ba550>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70a9159b0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70a906ac8>,\n",
       " <keras.layers.merge.Add at 0x7ff70a8b6d30>,\n",
       " <keras.layers.core.Activation at 0x7ff70a818518>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70a831208>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70a7f4908>,\n",
       " <keras.layers.core.Activation at 0x7ff70a74fe10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70a732d68>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70a683978>,\n",
       " <keras.layers.core.Activation at 0x7ff70a668518>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70a5c3978>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70a633a90>,\n",
       " <keras.layers.merge.Add at 0x7ff70a563d30>,\n",
       " <keras.layers.core.Activation at 0x7ff70a533f28>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70a533f98>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70a4a28d0>,\n",
       " <keras.layers.core.Activation at 0x7ff70a478dd8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70a3dce10>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70a3b3940>,\n",
       " <keras.layers.core.Activation at 0x7ff70a3164e0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70a2f2940>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70a2e2a58>,\n",
       " <keras.layers.merge.Add at 0x7ff70a212cf8>,\n",
       " <keras.layers.core.Activation at 0x7ff70a1ddf60>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70a1ddeb8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70a14c898>,\n",
       " <keras.layers.core.Activation at 0x7ff70a126da0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff70a08cfd0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70a0657f0>,\n",
       " <keras.layers.core.Activation at 0x7ff709fc34a8>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff709f9f908>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff709f3ecc0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff709f8ea20>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff709e88f28>,\n",
       " <keras.layers.merge.Add at 0x7ff709d8ef60>,\n",
       " <keras.layers.core.Activation at 0x7ff709da7438>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff709da72b0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff709d029e8>,\n",
       " <keras.layers.core.Activation at 0x7ff709ce1ef0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff709c50a90>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff709c42ba8>,\n",
       " <keras.layers.core.Activation at 0x7ff709befe10>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff709b6c240>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff709b27b70>,\n",
       " <keras.layers.merge.Add at 0x7ff709a86710>,\n",
       " <keras.layers.core.Activation at 0x7ff709a5ac88>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff709a5aac8>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff709a7f2b0>,\n",
       " <keras.layers.core.Activation at 0x7ff7099ae780>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff709900a58>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff70996fb70>,\n",
       " <keras.layers.core.Activation at 0x7ff70986dfd0>,\n",
       " <keras.layers.convolutional.Conv2D at 0x7ff7098182b0>,\n",
       " <keras.layers.normalization.BatchNormalization at 0x7ff7097d7b38>,\n",
       " <keras.layers.merge.Add at 0x7ff7097b96d8>,\n",
       " <keras.layers.core.Activation at 0x7ff709707c50>,\n",
       " <keras.layers.pooling.AveragePooling2D at 0x7ff709707a90>,\n",
       " <keras.layers.pooling.GlobalAveragePooling2D at 0x7ff7096e8da0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "8wF_XDlwdaUW",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "id": "UNgjxVA-daUY",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "OLFqQu1PdaUc",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "deletable": true,
    "id": "z89Zv5hWdaUd",
    "new_sheet": false,
    "outputId": "cfd83c25-ee03-416c-c0fa-0cdeef990523",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 4,098\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "l5VbHHYDdaUh",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "deletable": true,
    "id": "eh5nVo3udaUi",
    "new_sheet": false,
    "outputId": "e7f0262b-4b7a-4a8c-80fb-b390f0540e30",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "o5UyMu6wdaUo",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "id": "e5oN3m56daUp",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = 30\n",
    "#= len(train_generator)\n",
    "steps_per_epoch_validation = 30\n",
    "#= len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "TBgpPt4-daUt",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "colab_type": "code",
    "deletable": true,
    "id": "RrRTvvP_daUt",
    "new_sheet": false,
    "outputId": "f04f023e-ce0b-40b2-d7a3-3f4f8cdfdd94",
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "X-dHbckQdaUx",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "mgMQdJCQdaUz",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "colab": {},
    "colab_type": "code",
    "deletable": true,
    "id": "DN4voZOHdaU0",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# model.save('classifier_resnet_model.h5')\n",
    "\n",
    "from keras.models import load_model\n",
    "classifier_resnet_model = load_model('classifier_resnet_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 4098      \n",
      "=================================================================\n",
      "Total params: 23,591,810\n",
      "Trainable params: 23,538,690\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_resnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "XPCEhPG9daU5",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "EstHMYGydaU6",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "Oh94n_v2daU7",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "colab_type": "text",
    "deletable": true,
    "id": "MfpIUGgPdaU9",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DL0321EN-3-1-Pretrained-Models-py-v1.0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
